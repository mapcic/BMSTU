\chapter{Математический аппарат для моделирования}
\section{Метод конечных разностей}
Суть метода конечных разностей заключается в аппроксимации дифференциальных операторов отношением конечных разностей. Так например производную некоторой функции $y(x)$ в точке $x_{0}$ ($\dot{y}(x_{0})$) можно представить:
\begin{gather}
	\dot{y}_{+}(x_{0}) = \frac{d}{dx}y(x_{0}) = \frac{y(x_{0} + \Delta x) - y(x_{0})}{\Delta x };\\
	\dot{y}_{-}(x_{0}) = \frac{d}{dx}y(x_{0}) = \frac{ y(x_{0}) - y(x_{0} - \Delta x)}{\Delta x };\\
	\dot{y}_{-}(x_{0}) = \dot{y}_{+}(x_{0}) = \frac{d}{dx}y(x_{0}),
\end{gather}
\begin{conditions}
	$\dot{y}_{-}$ & производная слева;\\
	$\dot{y}_{+}$ & производная справа;\\
	$\Delta x$ & приращение аргумента (шаг сетки).
\end{conditions}

$\Delta x$ -- это шаг нашей конечно-разностной схемы (аппроксимации). Если шаг сетки постоянен, то говорят о регулярной сетке, иначе о нерегулярной. Мы будем рассматривать только регулярные сетки. Далее вместо $\Delta x$ будет использовать $\Delta$.

Из выше сказанного можно найти трехточечную аппроксимацию второй производной $y(x)$:
\begin{gather}
	\frac{d^{2}}{dx^{2}}y(x_{0}) = \frac{\dot{y}_{+} - \dot{y}_{-}}{\Delta} = \frac{y(x_{0} + \Delta) - 2y(x_{0}) + y(x_{0} - \Delta)}{ \Delta^{2}}.
\end{gather}